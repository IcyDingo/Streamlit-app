{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests as r\n",
    "import time \n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score,silhouette_samples\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import plotly.express as px \n",
    "import plotly.io as pio \n",
    "pio.renderers.default = \"browser\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meanRetAn(data):             \n",
    "    Result = 1\n",
    "    \n",
    "    for i in range(len(data.index)):\n",
    "        Result *= (1+data.iloc[i,:])\n",
    "        \n",
    "    Result = Result**(1/float(len(data.index)/52))-1\n",
    "     \n",
    "    return(Result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1577\n"
     ]
    }
   ],
   "source": [
    "#getting etf tickers from etf in etf info\n",
    "#etf_info = pd.read_csv(\"ETFs_info.csv\")\n",
    "yahoo_cat_df = pd.read_csv(\"yahoo_cat_df.csv\",index_col=\"Ticker\")\n",
    "week_df_900 = pd.read_csv(\"WeeklyReturns.csv\", index_col=\"Date\")\n",
    "etf_funda_df = pd.read_csv(\"etf_fundamental.csv\", index_col=\"Unnamed: 0\") # result from the fetcing code below\n",
    "etf_funda_df = pd.merge(yahoo_cat_df,etf_funda_df, right_index=True,left_index=True, how=\"right\")\n",
    "etf_funda_df[\"pe\"].loc[etf_funda_df['Category'] == \"Trading--Inverse Equity\"] = -1\n",
    "etf_funda_df[\"pcf\"].loc[etf_funda_df['Category'] == \"Trading--Inverse Equity\"] = -1\n",
    "etf_funda_df[\"ps\"].loc[etf_funda_df['Category'] == \"Trading--Inverse Equity\"] = -1\n",
    "etf_funda_df[\"pb\"].loc[etf_funda_df['Category'] == \"Trading--Inverse Equity\"] = -1\n",
    "etf_funda_df[\"pe\"].loc[etf_funda_df['Category'] == \"Trading--Leveraged Equity\"] = -5\n",
    "etf_funda_df[\"pcf\"].loc[etf_funda_df['Category'] == \"Trading--Leveraged Equity\"] = -5\n",
    "etf_funda_df[\"ps\"].loc[etf_funda_df['Category'] == \"Trading--Leveraged Equity\"] = -5\n",
    "etf_funda_df[\"pb\"].loc[etf_funda_df['Category'] == \"Trading--Leveraged Equity\"] = -5\n",
    "etf_funda_df.drop(columns=\"Category\", inplace=True)\n",
    "print(len(etf_funda_df))\n",
    "etf_funda_df = etf_funda_df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dff = pd.DataFrame(mu_ga).rename(columns={\"2016-08-05\":\"AnnRet\"})\n",
    "# dff[\"Annual Std\"] = week_df_900.std(axis=0) * np.sqrt(52)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#etf_merged.dropna(inplace=True)\n",
    "etf_merged = etf_funda_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # fetching fundamentals from yahoo finance on each etf\n",
    "# ticker = list(yahoo_cat_df.index)\n",
    "# test = {}\n",
    "# for i in tqdm(ticker):\n",
    "#     test[i] = {}\n",
    "#     lnk = f\"https://finance.yahoo.com/quote/{i}/holdings?p={i}\"\n",
    "#     con = r.get(lnk)\n",
    "#     soup = BeautifulSoup(con.text, \"lxml\")\n",
    "#     try: \n",
    "\n",
    "\n",
    "#         test[i][\"pe\"] = soup.find('span', {\"data-reactid\":\"131\"}).get_text()\n",
    "#         test[i][\"pb\"] = soup.find('span', {\"data-reactid\":\"136\"}).get_text()\n",
    "#         test[i][\"pcf\"] = soup.find('span', {\"data-reactid\":\"146\"}).get_text()\n",
    "#         test[i][\"ps\"] = soup.find('span', {\"data-reactid\":\"141\"}).get_text()\n",
    "#     except:\n",
    "#         test[i][\"pe\"] = np.nan\n",
    "#         test[i][\"pb\"] = np.nan\n",
    "#         test[i][\"pcf\"] = np.nan\n",
    "#         test[i][\"ps\"] = np.nan\n",
    "# a = pd.DataFrame(test).T\n",
    "# a.to_csv(\"etf_fundamental.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing the features\n",
    "cluster_stand = StandardScaler().fit_transform(etf_merged)\n",
    "cluster_stand = pd.DataFrame(cluster_stand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reducing dementionality of the data features to be explanined by 2 components for visualization and clustering \n",
    "X_embedded = TSNE(n_components=2, random_state=400).fit_transform(cluster_stand)\n",
    "cluster_stand[\"dim1\"] = X_embedded[:,0]\n",
    "cluster_stand[\"dim2\"] = X_embedded[:,1]\n",
    "# cluster_stand = StandardScaler().fit_transform(etf_merged)\n",
    "# cluster_stand = pd.DataFrame(etf_merged)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "For n_clusters = 2 The average silhouette_score is : 0.4437416238983516\n",
      "For n_clusters = 3 The average silhouette_score is : 0.4768930952236609\n",
      "For n_clusters = 4 The average silhouette_score is : 0.4663594218771804\n",
      "For n_clusters = 5 The average silhouette_score is : 0.5120947574758284\n",
      "For n_clusters = 6 The average silhouette_score is : 0.532826100163838\n",
      "For n_clusters = 7 The average silhouette_score is : 0.5128123772992926\n",
      "For n_clusters = 8 The average silhouette_score is : 0.4992627149746311\n",
      "For n_clusters = 9 The average silhouette_score is : 0.4881527666984056\n",
      "For n_clusters = 10 The average silhouette_score is : 0.49540928769275716\n",
      "For n_clusters = 11 The average silhouette_score is : 0.48372961706526574\n",
      "For n_clusters = 12 The average silhouette_score is : 0.4777085157850483\n",
      "For n_clusters = 13 The average silhouette_score is : 0.4843768587342331\n"
     ]
    }
   ],
   "source": [
    "#finding the \"optimal\" cluster \n",
    "iini = []\n",
    "clus = []\n",
    "for n_clusters in range(2,14):\n",
    "        clusterer = KMeans(n_clusters=n_clusters, random_state=10,n_init=20, algorithm=\"elkan\",init='k-means++')\n",
    "        cluster_labels = clusterer.fit_predict(cluster_stand)\n",
    "\n",
    "        # The silhouette_score gives the average value for all the samples.\n",
    "        # This gives a perspective into the density and separation of the formed\n",
    "        # clusters\n",
    "        silhouette_avg = silhouette_score(cluster_stand, cluster_labels)\n",
    "        print(\"For n_clusters =\", n_clusters,\n",
    "            \"The average silhouette_score is :\", silhouette_avg)\n",
    "        clus.append(n_clusters)\n",
    "        iini.append(clusterer.inertia_)\n",
    "fig = px.line(y=iini,x=clus)\n",
    "fig.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "km = KMeans(\n",
    "    n_clusters=6, init='k-means++',\n",
    "    n_init=20, max_iter=1000, \n",
    "    tol=1e-04, random_state=10, algorithm=\"elkan\"\n",
    ")\n",
    "clustered = km.fit_predict(cluster_stand)\n",
    "cluster_stand[\"cluster\"] = clustered\n",
    "cluster_stand[\"dim1\"] = X_embedded[:,0]\n",
    "cluster_stand[\"dim2\"] = X_embedded[:,1]\n",
    "fig = px.scatter(cluster_stand,x=\"dim1\", y=\"dim2\", color=\"cluster\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "week_df_900 = pd.merge(week_df_900.T,yahoo_cat_df, right_index=True, left_index= True, how=\"inner\")\n",
    "week_df_900 = week_df_900.iloc[:,:-1].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "etf_merged[\"cluster\"] = clustered\n",
    "list1_as_set = set(week_df_900.columns)\n",
    "intersection = list1_as_set.intersection(list(etf_funda_df.index))\n",
    "intersection_as_list = list(intersection)\n",
    "fund_min = etf_merged.loc[intersection_as_list,:]\n",
    "week_df_900 = week_df_900[intersection_as_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfff = pd.DataFrame(index=week_df_900.index)\n",
    "dff_dict = {}\n",
    "for i in fund_min[\"cluster\"].unique():\n",
    "    tickers = list(fund_min[fund_min[\"cluster\"]==i].index)\n",
    "    n_assets = len(tickers)\n",
    "    portfolio_weights_ew = np.repeat(1/n_assets, n_assets)\n",
    "    port_weekly_return = week_df_900[tickers].mul(portfolio_weights_ew,axis=1).sum(axis=1)\n",
    "    dfff[i] = port_weekly_return\n",
    "    \n",
    "cumsum = dfff.cumsum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_sort = pd.DataFrame(dfff.std(axis=0)*np.sqrt(52)).reset_index().sort_values(by=[0], ascending=False)[\"index\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   index         0\n",
       "2      4  0.486448\n",
       "4      0  0.383660\n",
       "3      5  0.227008\n",
       "5      3  0.191325\n",
       "0      2  0.185675\n",
       "1      1  0.179898"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>4</td>\n      <td>0.486448</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0.383660</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5</td>\n      <td>0.227008</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>3</td>\n      <td>0.191325</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>0.185675</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0.179898</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "pd.DataFrame(dfff.std(axis=0)*np.sqrt(52)).reset_index().sort_values(by=[0], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumsum[\"SPY\"]= week_df_900[\"SPY\"].cumsum(axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                   2         1         4         5         0         3  \\\n",
       "2016-08-05  0.000060 -0.001394  0.014341  0.008903 -0.015368  0.004237   \n",
       "2016-08-12  0.013185  0.007512  0.033149  0.015900 -0.030839  0.009462   \n",
       "2016-08-19  0.014469  0.008427  0.037784  0.025045 -0.039478  0.010276   \n",
       "2016-08-26  0.004608  0.000307  0.005164  0.016371 -0.014646  0.004384   \n",
       "2016-09-02  0.016023  0.010510  0.031707  0.023125 -0.035351  0.011258   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "2020-03-20 -0.152343 -0.008503 -0.166134 -0.285710 -0.085414  0.182712   \n",
       "2020-03-27 -0.051788  0.097563  0.077140 -0.193538 -0.321657  0.290444   \n",
       "2020-04-03 -0.085751  0.067011 -0.001871 -0.219320 -0.285898  0.264435   \n",
       "2020-04-17  0.034837  0.197809  0.368406 -0.054231 -0.547107  0.420024   \n",
       "2020-04-24  0.025946  0.188600  0.352365 -0.036434 -0.549790  0.413317   \n",
       "\n",
       "                 SPY  \n",
       "2016-08-05  0.004882  \n",
       "2016-08-12  0.006165  \n",
       "2016-08-19  0.006532  \n",
       "2016-08-26  0.000812  \n",
       "2016-09-02  0.005782  \n",
       "...              ...  \n",
       "2020-03-20  0.177057  \n",
       "2020-03-27  0.284662  \n",
       "2020-04-03  0.264024  \n",
       "2020-04-17  0.418946  \n",
       "2020-04-24  0.406142  \n",
       "\n",
       "[191 rows x 7 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>2</th>\n      <th>1</th>\n      <th>4</th>\n      <th>5</th>\n      <th>0</th>\n      <th>3</th>\n      <th>SPY</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2016-08-05</th>\n      <td>0.000060</td>\n      <td>-0.001394</td>\n      <td>0.014341</td>\n      <td>0.008903</td>\n      <td>-0.015368</td>\n      <td>0.004237</td>\n      <td>0.004882</td>\n    </tr>\n    <tr>\n      <th>2016-08-12</th>\n      <td>0.013185</td>\n      <td>0.007512</td>\n      <td>0.033149</td>\n      <td>0.015900</td>\n      <td>-0.030839</td>\n      <td>0.009462</td>\n      <td>0.006165</td>\n    </tr>\n    <tr>\n      <th>2016-08-19</th>\n      <td>0.014469</td>\n      <td>0.008427</td>\n      <td>0.037784</td>\n      <td>0.025045</td>\n      <td>-0.039478</td>\n      <td>0.010276</td>\n      <td>0.006532</td>\n    </tr>\n    <tr>\n      <th>2016-08-26</th>\n      <td>0.004608</td>\n      <td>0.000307</td>\n      <td>0.005164</td>\n      <td>0.016371</td>\n      <td>-0.014646</td>\n      <td>0.004384</td>\n      <td>0.000812</td>\n    </tr>\n    <tr>\n      <th>2016-09-02</th>\n      <td>0.016023</td>\n      <td>0.010510</td>\n      <td>0.031707</td>\n      <td>0.023125</td>\n      <td>-0.035351</td>\n      <td>0.011258</td>\n      <td>0.005782</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2020-03-20</th>\n      <td>-0.152343</td>\n      <td>-0.008503</td>\n      <td>-0.166134</td>\n      <td>-0.285710</td>\n      <td>-0.085414</td>\n      <td>0.182712</td>\n      <td>0.177057</td>\n    </tr>\n    <tr>\n      <th>2020-03-27</th>\n      <td>-0.051788</td>\n      <td>0.097563</td>\n      <td>0.077140</td>\n      <td>-0.193538</td>\n      <td>-0.321657</td>\n      <td>0.290444</td>\n      <td>0.284662</td>\n    </tr>\n    <tr>\n      <th>2020-04-03</th>\n      <td>-0.085751</td>\n      <td>0.067011</td>\n      <td>-0.001871</td>\n      <td>-0.219320</td>\n      <td>-0.285898</td>\n      <td>0.264435</td>\n      <td>0.264024</td>\n    </tr>\n    <tr>\n      <th>2020-04-17</th>\n      <td>0.034837</td>\n      <td>0.197809</td>\n      <td>0.368406</td>\n      <td>-0.054231</td>\n      <td>-0.547107</td>\n      <td>0.420024</td>\n      <td>0.418946</td>\n    </tr>\n    <tr>\n      <th>2020-04-24</th>\n      <td>0.025946</td>\n      <td>0.188600</td>\n      <td>0.352365</td>\n      <td>-0.036434</td>\n      <td>-0.549790</td>\n      <td>0.413317</td>\n      <td>0.406142</td>\n    </tr>\n  </tbody>\n</table>\n<p>191 rows × 7 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "cumsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot = px.line(cumsum, x = cumsum.index, y = cumsum.columns) \n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "4\nNumber of Assets: 75\nPrice/Sales -5.0\nPrice/Book -5.0\nPrice/Casflow -5.0\nPrice/Earnings -5.0\n-5.0\n--------------------\n0\nNumber of Assets: 65\nPrice/Sales -1.0\nPrice/Book -1.0\nPrice/Casflow -1.0\nPrice/Earnings -1.0\n-1.0\n--------------------\n5\nNumber of Assets: 161\nPrice/Sales 1.9332919254658385\nPrice/Book 1.8878260869565218\nPrice/Casflow 2.8816770186335408\nPrice/Earnings 4.156832298136646\n2.7149068322981367\n--------------------\n3\nSPY in: 3\nNumber of Assets: 432\nPrice/Sales 3.550694444444445\nPrice/Book 5.695324074074074\nPrice/Casflow 18.94199074074074\nPrice/Earnings 29.77212962962963\n14.490034722222223\n--------------------\n2\nNumber of Assets: 389\nPrice/Sales 1.0327506426735218\nPrice/Book 1.567146529562982\nPrice/Casflow 7.349588688946015\nPrice/Earnings 16.474884318766065\n6.6060925449871455\n--------------------\n1\nNumber of Assets: 438\nPrice/Sales 1.7493150684931509\nPrice/Book 2.5243835616438353\nPrice/Casflow 11.68566210045662\nPrice/Earnings 22.511050228310502\n9.617602739726028\n--------------------\n"
     ]
    }
   ],
   "source": [
    "for i in cluster_sort:\n",
    "    print(i)\n",
    "    if \"SPY\" in etf_merged[ etf_merged[\"cluster\"]==i].index: \n",
    "        print(\"SPY in:\",i)\n",
    "    print(\"Number of Assets:\",len(etf_merged[ etf_merged[\"cluster\"]==i]))\n",
    "    print(\"Price/Sales\",etf_merged[ etf_merged[\"cluster\"]==i][\"ps\"].mean()) \n",
    "    print(\"Price/Book\",etf_merged[ etf_merged[\"cluster\"]==i][\"pb\"].mean()) \n",
    "    print(\"Price/Casflow\",etf_merged[ etf_merged[\"cluster\"]==i][\"pcf\"].mean()) \n",
    "    print(\"Price/Earnings\",etf_merged[ etf_merged[\"cluster\"]==i][\"pe\"].mean()) \n",
    "    avg = etf_merged[ etf_merged[\"cluster\"]==i][\"ps\"].mean()+etf_merged[ etf_merged[\"cluster\"]==i][\"pb\"].mean()+etf_merged[ etf_merged[\"cluster\"]==i][\"pcf\"].mean()+etf_merged[          etf_merged[\"cluster\"]==i][\"pe\"].mean()\n",
    "    print(avg/4)\n",
    "    print(20*\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame(dfff.std(axis=0)*np.sqrt(52)).reset_index().sort_values(by=[0], ascending=False)\n",
    "annn = pd.DataFrame(meanRetAn(dfff)).reset_index().rename(columns={\"2016-08-05\":\"AnnRet\"})\n",
    "dingo = pd.merge(test,annn,on=\"index\",how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "yahoo_df = pd.read_csv(\"yahoo_cat_df.csv\", index_col=\"Ticker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_df = pd.merge(etf_merged,yahoo_cat_df,right_index=True,left_index=True,how=\"inner\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "4\n75 75\nTrading--Leveraged Equity    75\nName: Category, dtype: int64\n------------------------------\n0\n65 65\nTrading--Inverse Equity    65\nName: Category, dtype: int64\n------------------------------\n5\n161 134\nFinancial                     30\nEquity Energy                 21\nEnergy Limited Partnership    14\nHealth                        11\nMiscellaneous Sector           8\nMiscellaneous Region           6\nTechnology                     6\nLarge Growth                   5\nWorld Stock                    4\nConsumer Cyclical              4\nLarge Blend                    3\nEurope Stock                   3\nLarge Value                    3\nOption Writing                 2\nBear Market                    2\nNatural Resources              2\nSmall Growth                   2\nEquity Precious Metals         2\nForeign Large Value            1\nPacific/Asia ex-Japan Stk      1\nDiversified Emerging Mkts      1\nChina Region                   1\nSmall Blend                    1\nNontraditional Bond            1\nName: Category, dtype: int64\n------------------------------\n3\n432 379\nLarge Blend                  98\nTechnology                   52\nLarge Growth                 43\nOption Writing               29\nHealth                       24\nMid-Cap Growth               18\nChina Region                 14\nConsumer Cyclical            12\nForeign Large Growth         11\nMiscellaneous Sector         10\nIndustrials                   9\nMid-Cap Blend                 7\nConsumer Defensive            7\nLarge Value                   7\nDiversified Emerging Mkts     5\nSmall Growth                  5\nWorld Stock                   4\nIndia Equity                  4\nCommunications                3\nMiscellaneous Region          3\nNatural Resources             3\nLong-Short Equity             3\nEquity Energy                 2\nEurope Stock                  2\nEquity Precious Metals        1\nForeign Small/Mid Blend       1\nForeign Small/Mid Growth      1\nFinancial                     1\nName: Category, dtype: int64\n------------------------------\n2\n389 345\nMiscellaneous Region             44\nDiversified Emerging Mkts        38\nForeign Large Value              34\nLarge Value                      27\nSmall Blend                      26\nForeign Large Blend              21\nSmall Value                      20\nJapan Stock                      16\nMid-Cap Value                    16\nChina Region                     10\nNatural Resources                10\nEnergy Limited Partnership        9\nEurope Stock                      8\nForeign Small/Mid Blend           7\nForeign Small/Mid Value           7\nWorld Stock                       7\nLatin America Stock               6\nMid-Cap Blend                     5\nConsumer Cyclical                 4\nEquity Precious Metals            4\nOption Writing                    3\nIndustrials                       3\nDiversified Pacific/Asia          3\nIndia Equity                      2\nLarge Blend                       2\nUtilities                         2\nMiscellaneous Sector              2\nConsumer Defensive                2\nSmall Growth                      1\nAllocation--70% to 85% Equity     1\nMid-Cap Growth                    1\nLong-Short Equity                 1\nCommunications                    1\nPacific/Asia ex-Japan Stk         1\nHealth                            1\nName: Category, dtype: int64\n------------------------------\n1\n438 366\nLarge Value                  45\nLarge Blend                  40\nForeign Large Blend          38\nMid-Cap Blend                30\nDiversified Emerging Mkts    21\nMiscellaneous Region         19\nSmall Blend                  19\nWorld Stock                  17\nNatural Resources            17\nEurope Stock                 14\nIndustrials                  11\nChina Region                 10\nUtilities                     8\nInfrastructure                7\nMid-Cap Value                 7\nTechnology                    7\nSmall Growth                  7\nCommunications                6\nConsumer Cyclical             6\nPacific/Asia ex-Japan Stk     5\nForeign Large Growth          4\nEquity Precious Metals        4\nMid-Cap Growth                4\nHealth                        3\nIndia Equity                  3\nOption Writing                3\nLarge Growth                  3\nConsumer Defensive            3\nMiscellaneous Sector          2\nReal Estate                   1\nDiversified Pacific/Asia      1\nTactical Allocation           1\nName: Category, dtype: int64\n------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in cluster_sort:\n",
    "    print(i)\n",
    "    print(len(com_df[com_df[\"cluster\"]==i]), sum(com_df[com_df[\"cluster\"]==i][\"Category\"].value_counts()))\n",
    "    print(com_df[com_df[\"cluster\"]==i][\"Category\"].value_counts())\n",
    "    print(30*\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "funda_cluster = {}\n",
    "for i,x in zip(cluster_sort,[\"Market Leveraged ETF\",\"Market Inverse ETF\",\"Low Fundamental ETF’s (Energy, Health,Finance)\",\"High Fundamental Broad Market\",\"Low Fundamental Broad Market\",\"Mid Fundamental Broad Market\"]):\n",
    "    funda_cluster[i] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{4: 'Market Leveraged ETF',\n",
       " 0: 'Market Inverse ETF',\n",
       " 5: 'Low Fundamental ETF’s (Energy, Health,Finance)',\n",
       " 3: 'High Fundamental Broad Market',\n",
       " 2: 'Low Fundamentals Broad Market',\n",
       " 1: 'Mid Fundamentals Broad Market'}"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "funda_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_df[\"Fundamental Cluster\"] = com_df[\"cluster\"].apply(lambda x: funda_cluster[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_df.to_csv(\"Fundamental_Clustering.csv\", index_label=\"Ticker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "fundamental_df_cluster = com_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           pe    pb    pcf    ps  cluster                   Category  \\\n",
       "Ticker                                                                 \n",
       "SPY     27.93  4.00  16.31  2.74        3                Large Blend   \n",
       "IVV     27.16  3.81  16.08  2.62        3                Large Blend   \n",
       "VTI     27.49  3.81  15.92  2.58        3                Large Blend   \n",
       "VOO     27.94  4.00  16.32  2.75        3                Large Blend   \n",
       "QQQ     34.42  7.93  21.00  4.64        3               Large Growth   \n",
       "...       ...   ...    ...   ...      ...                        ...   \n",
       "DMAY    27.94  4.00  16.31  2.74        3                        NaN   \n",
       "NJUL    34.65  7.86  21.31  4.77        3                Large Blend   \n",
       "BMAY    27.17  3.81  16.08  2.62        3                Large Blend   \n",
       "FLV     21.89  2.45  15.00  2.43        1                Large Value   \n",
       "GSEE    18.33  1.99  10.76  1.57        1  Diversified Emerging Mkts   \n",
       "\n",
       "                  Fundamental Cluster  \n",
       "Ticker                                 \n",
       "SPY     High Fundamental Broad Market  \n",
       "IVV     High Fundamental Broad Market  \n",
       "VTI     High Fundamental Broad Market  \n",
       "VOO     High Fundamental Broad Market  \n",
       "QQQ     High Fundamental Broad Market  \n",
       "...                               ...  \n",
       "DMAY    High Fundamental Broad Market  \n",
       "NJUL    High Fundamental Broad Market  \n",
       "BMAY    High Fundamental Broad Market  \n",
       "FLV     Mid Fundamentals Broad Market  \n",
       "GSEE    Mid Fundamentals Broad Market  \n",
       "\n",
       "[1560 rows x 7 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pe</th>\n      <th>pb</th>\n      <th>pcf</th>\n      <th>ps</th>\n      <th>cluster</th>\n      <th>Category</th>\n      <th>Fundamental Cluster</th>\n    </tr>\n    <tr>\n      <th>Ticker</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>SPY</th>\n      <td>27.93</td>\n      <td>4.00</td>\n      <td>16.31</td>\n      <td>2.74</td>\n      <td>3</td>\n      <td>Large Blend</td>\n      <td>High Fundamental Broad Market</td>\n    </tr>\n    <tr>\n      <th>IVV</th>\n      <td>27.16</td>\n      <td>3.81</td>\n      <td>16.08</td>\n      <td>2.62</td>\n      <td>3</td>\n      <td>Large Blend</td>\n      <td>High Fundamental Broad Market</td>\n    </tr>\n    <tr>\n      <th>VTI</th>\n      <td>27.49</td>\n      <td>3.81</td>\n      <td>15.92</td>\n      <td>2.58</td>\n      <td>3</td>\n      <td>Large Blend</td>\n      <td>High Fundamental Broad Market</td>\n    </tr>\n    <tr>\n      <th>VOO</th>\n      <td>27.94</td>\n      <td>4.00</td>\n      <td>16.32</td>\n      <td>2.75</td>\n      <td>3</td>\n      <td>Large Blend</td>\n      <td>High Fundamental Broad Market</td>\n    </tr>\n    <tr>\n      <th>QQQ</th>\n      <td>34.42</td>\n      <td>7.93</td>\n      <td>21.00</td>\n      <td>4.64</td>\n      <td>3</td>\n      <td>Large Growth</td>\n      <td>High Fundamental Broad Market</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>DMAY</th>\n      <td>27.94</td>\n      <td>4.00</td>\n      <td>16.31</td>\n      <td>2.74</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>High Fundamental Broad Market</td>\n    </tr>\n    <tr>\n      <th>NJUL</th>\n      <td>34.65</td>\n      <td>7.86</td>\n      <td>21.31</td>\n      <td>4.77</td>\n      <td>3</td>\n      <td>Large Blend</td>\n      <td>High Fundamental Broad Market</td>\n    </tr>\n    <tr>\n      <th>BMAY</th>\n      <td>27.17</td>\n      <td>3.81</td>\n      <td>16.08</td>\n      <td>2.62</td>\n      <td>3</td>\n      <td>Large Blend</td>\n      <td>High Fundamental Broad Market</td>\n    </tr>\n    <tr>\n      <th>FLV</th>\n      <td>21.89</td>\n      <td>2.45</td>\n      <td>15.00</td>\n      <td>2.43</td>\n      <td>1</td>\n      <td>Large Value</td>\n      <td>Mid Fundamentals Broad Market</td>\n    </tr>\n    <tr>\n      <th>GSEE</th>\n      <td>18.33</td>\n      <td>1.99</td>\n      <td>10.76</td>\n      <td>1.57</td>\n      <td>1</td>\n      <td>Diversified Emerging Mkts</td>\n      <td>Mid Fundamentals Broad Market</td>\n    </tr>\n  </tbody>\n</table>\n<p>1560 rows × 7 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "pd.read_csv(\"Fundamental_Clustering.csv\", index_col=\"Ticker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}